{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e959e-a819-4af5-8ad2-db5cf77f969e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.86.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.91.0-py2.py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.24.2)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.19.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.31.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.14.2)\n",
      "Requirement already satisfied: shapely<3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.7)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.11.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (4.13.0)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.49.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform) (1.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0->google-cloud-aiplatform) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2025.1.31)\n",
      "Downloading google_cloud_aiplatform-1.91.0-py2.py3-none-any.whl (7.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-cloud-aiplatform\n",
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed google-cloud-aiplatform-1.91.0\n",
      "Requirement already satisfied: google-cloud-aiplatform in ./.local/lib/python3.10/site-packages (1.91.0)\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.24.2)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.19.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.31.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.14.2)\n",
      "Requirement already satisfied: shapely<3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.7)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.11.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (4.13.0)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.49.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform) (1.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely<3.0.0->google-cloud-aiplatform) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2025.1.31)\n",
      "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "\u001b[33m  WARNING: The script pymupdf is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pymupdf-1.25.5\n"
     ]
    }
   ],
   "source": [
    "# INSTALAMOS VERTEX AI SDK PARA PYTHON\n",
    "\n",
    "!pip3 install --upgrade --user google-cloud-aiplatform\n",
    "!pip3 install --upgrade --user google-cloud-aiplatform pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864cef62-bfea-4843-b2a3-0b19bc00a0df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REESTABLECEMOS EL KERNEL\n",
    "\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e078e2-2891-42ed-95f7-ce31795045d0",
   "metadata": {},
   "source": [
    "### Define Google Cloud project information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ca78d-1320-49dd-8c43-3d5608f47c61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your project ID is: qwiklabs-gcp-01-4b4df9e68e91\n"
     ]
    }
   ],
   "source": [
    "#INFORMACIÓN DEL PROYECTO\n",
    "\n",
    "import sys\n",
    "\n",
    "PROJECT_ID = \"qwiklabs-gcp-01-4b4df9e68e91\" \n",
    "LOCATION = \"us-east4\" \n",
    "\n",
    "\n",
    "if \"google.colab\" not in sys.modules:\n",
    "    import subprocess\n",
    "\n",
    "    PROJECT_ID = subprocess.check_output(\n",
    "        [\"gcloud\", \"config\", \"get-value\", \"project\"], text=True\n",
    "    ).strip()\n",
    "\n",
    "print(f\"Your project ID is: {PROJECT_ID}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48216434",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI\n",
    "\n",
    "Initialize the Vertex AI SDK for Python for your project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ded7d-13b9-42ff-87dc-0b5c998f884f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INICIAMOS VERTEX AI\n",
    "\n",
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb712712-c7fb-43ef-be19-2497d610111c",
   "metadata": {},
   "source": [
    "## Task 1. Generating Multimodal Insights with Gemini\n",
    "\n",
    "Gemini is multimodal model that supports multimodal prompts. You can include text, image(s), and video in your prompt requests and get text or code responses.\n",
    "\n",
    "To complete Task 1, follow the instructions at the top of each notebook cell:\n",
    "* Run the cells with the comment \"RUN THIS CELL AS IS\".\n",
    "* Complete and run the cells with the comment \"COMPLETE THE MISSING PART AND RUN THIS CELL\".\n",
    "\n",
    "__Note__: Ensure you can see the weather related data in the response that is printed.\n",
    "\n",
    "\n",
    "### Setup and requirements for Task 1\n",
    "\n",
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d32222-695d-4993-bdc4-fde7bc7948f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPORTAMOS LAS LIBRERIAS\n",
    "\n",
    "from vertexai.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435fad59-d08b-4aef-8230-7f567643ce14",
   "metadata": {},
   "source": [
    "#### Load Gemini 2.0 Flash Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63f204-6acc-41aa-ac25-45544d5c3888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CARGAMOS EL MODELO\n",
    "\n",
    "multimodal_model = GenerativeModel(\"gemini-2.0-flash-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c3a051-d567-4146-b428-fcb285c6485d",
   "metadata": {},
   "source": [
    "#### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de36ca-ded6-46e4-99e9-4ed2fc88ee8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DEFINIMOS LAS FUNCIONES\n",
    "\n",
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_images(\n",
    "    images: typing.Iterable[Image],\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    for image in images:\n",
    "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "        if pil_image.mode != \"RGB\":\n",
    "            \n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "        image_width, image_height = pil_image.size\n",
    "        if max_width < image_width or max_height < image_height:\n",
    "            \n",
    "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "        IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "def display_content_as_image(content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Image):\n",
    "        return False\n",
    "    display_images([content])\n",
    "    return True\n",
    "\n",
    "\n",
    "def display_content_as_video(content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Part):\n",
    "        return False\n",
    "    part = typing.cast(Part, content)\n",
    "    file_path = part.file_data.file_uri.removeprefix(\"gs://\")\n",
    "    video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
    "    IPython.display.display(IPython.display.Video(video_url, width=600))\n",
    "    return True\n",
    "\n",
    "\n",
    "def print_multimodal_prompt(contents: list[str | Image | Part]):\n",
    "    \"\"\"\n",
    "    Given contents that would be sent to Gemini,\n",
    "    output the full multimodal prompt for ease of readability.\n",
    "    \"\"\"\n",
    "    for content in contents:\n",
    "        if display_content_as_image(content):\n",
    "            continue\n",
    "        if display_content_as_video(content):\n",
    "            continue\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68bb17-db90-437a-89b1-d1fe1d2e715f",
   "metadata": {},
   "source": [
    "### Task 1.1. Image understanding across multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcae938-8299-4641-87d9-d78c3dc88ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "image_ask_first_1_url = \"https://storage.googleapis.com/spls/gsp520/Google_Branding/Ask_first_1.png\"\n",
    "image_dont_do_this_1_url = \"https://storage.googleapis.com/spls/gsp520/Google_Branding/Dont_do_this_1.png\"\n",
    "image_ask_first_1 = load_image_from_url(image_ask_first_1_url)\n",
    "image_dont_do_this_1 = load_image_from_url(image_dont_do_this_1_url)\n",
    "\n",
    "instructions = \"Instructions: Consider the following image that contains text:\"\n",
    "prompt1 = \"What is the title of this image\"\n",
    "prompt2 = \"\"\"\n",
    "Answer the question through these steps:\n",
    "Step 1: Identify the title of each image by using the filename of each image.\n",
    "Step 2: Describe the image.\n",
    "Step 3: For each image, describe the actions that a user is expected to take.\n",
    "Step 4: Extract the text from each image as a full sentence.\n",
    "Step 5: Describe the sentiment for each image with an explanation.\n",
    "\n",
    "Answer and describe the steps taken:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867dc55c",
   "metadata": {},
   "source": [
    "#### Create an input for the multimodal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390c4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "contents = [ \n",
    "    Part.from_text(\"Analiza estas imágenes brevemente en castellano:\"),\n",
    "    Part.from_image(image_ask_first_1),\n",
    "    Part.from_image(image_dont_do_this_1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4aad87",
   "metadata": {},
   "source": [
    "#### Generate responses from the multimodal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156c265",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responses = 'Aquí tienes un análisis breve de las imágenes:\n",
      "\n",
      "**Imagen 1:**\n",
      "\n",
      "*   **Contenido visual:** La imagen muestra un logo que combina dos \"X\" azules entrelazadas, el nombre \"SYSTEMERGER\" debajo, y una frase que indica que el producto/servicio facilita la integración de flujos de trabajo. Además, muestra iconos de aplicaciones como Gmail, Google Calendar y Google Drive, insinuando compatibilidad.\n",
      "*   **Texto complementario:** Advierte sobre el uso de iconos de productos, remitiendo a una guía de uso de iconos para saber si se pueden usar ciertos iconos de productos en asociación con el negocio.\n",
      "\n",
      "**Imagen 2:**\n",
      "\n",
      "*   **Contenido visual:** Muestra el logo de un restaurante llamado \"Frank's Crab Shack\" con una imagen de un ancla dentro de un círculo y el eslogan \"#1 Crab Restaurant in Northeastern Maine\" mostrado con el logo de Google al lado.\n",
      "*   **Texto complementario:** Advierte sobre la implicación de respaldo. Indica que no se use el logo de Google ni ningún elemento de su marca de manera que implique afiliación, respaldo o patrocinio donde no exista tal relación.\n",
      "\n",
      "En resumen, ambas imágenes forman parte de unas guías de marca donde se explica cómo utilizar iconos de productos o logos de otras marcas de forma correcta, evitando así implicar afiliaciones o respaldos inexistentes.'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "responses = multimodal_model.generate_content(contents)\n",
    "print(f\"responses = '{responses.text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28025b0",
   "metadata": {},
   "source": [
    "#### Display the prompt and responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92127e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Contenido (Prompt) ---\n",
      "- Contenido: Texto - 'Analiza estas imágenes brevemente en castellano:'\n",
      "- Contenido: Desconocido\n",
      "- Contenido: Desconocido\n",
      "\n",
      "--- Respuesta del Modelo ---\n",
      "Aquí tienes un análisis breve de las imágenes:\n",
      "\n",
      "**Imagen 1:**\n",
      "\n",
      "*   **Contenido visual:** La imagen muestra un logo que combina dos \"X\" azules entrelazadas, el nombre \"SYSTEMERGER\" debajo, y una frase que indica que el producto/servicio facilita la integración de flujos de trabajo. Además, muestra iconos de aplicaciones como Gmail, Google Calendar y Google Drive, insinuando compatibilidad.\n",
      "*   **Texto complementario:** Advierte sobre el uso de iconos de productos, remitiendo a una guía de uso de iconos para saber si se pueden usar ciertos iconos de productos en asociación con el negocio.\n",
      "\n",
      "**Imagen 2:**\n",
      "\n",
      "*   **Contenido visual:** Muestra el logo de un restaurante llamado \"Frank's Crab Shack\" con una imagen de un ancla dentro de un círculo y el eslogan \"#1 Crab Restaurant in Northeastern Maine\" mostrado con el logo de Google al lado.\n",
      "*   **Texto complementario:** Advierte sobre la implicación de respaldo. Indica que no se use el logo de Google ni ningún elemento de su marca de manera que implique afiliación, respaldo o patrocinio donde no exista tal relación.\n",
      "\n",
      "En resumen, ambas imágenes forman parte de unas guías de marca donde se explica cómo utilizar iconos de productos o logos de otras marcas de forma correcta, evitando así implicar afiliaciones o respaldos inexistentes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"--- Contenido (Prompt) ---\")\n",
    "for item in contents:\n",
    "    if hasattr(item, 'part_data') and hasattr(item.part_data, 'inline_data'):\n",
    "        if item.part_data.inline_data.mime_type.startswith('image'):\n",
    "            print(\"- Contenido: Imagen (tipo MIME: {})\".format(item.part_data.inline_data.mime_type))\n",
    "        elif item.part_data.inline_data.mime_type == 'text/plain':\n",
    "            print(\"- Contenido: Texto - '{}'\".format(item.text))\n",
    "        else:\n",
    "            print(\"- Contenido: Otro tipo de dato\")\n",
    "    elif hasattr(item, 'text'):\n",
    "        print(\"- Contenido: Texto - '{}'\".format(item.text))\n",
    "    else:\n",
    "        print(\"- Contenido: Desconocido\")\n",
    "\n",
    "print(\"\\n--- Respuesta del Modelo ---\")\n",
    "if hasattr(responses, 'text'):\n",
    "    print(responses.text)\n",
    "else:\n",
    "    print(\"La respuesta del modelo no contiene texto.\")\n",
    "    print(\"Respuesta completa del modelo:\", responses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5b2269-4982-4c77-85b7-b6413b17f293",
   "metadata": {},
   "source": [
    "### Task 1.2. Similarity/Differences between images\n",
    "\n",
    "#### Explore the variables of the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323aa40f-18dd-4454-a9f1-474d4c4c721b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_ask_first_3_url = \"https://storage.googleapis.com/spls/gsp520/Google_Branding/Ask_first_3.png\"\n",
    "image_dont_do_this_3_url =  \"https://storage.googleapis.com/spls/gsp520/Google_Branding/Dont_do_this_3.png\"\n",
    "image_ask_first_3 = load_image_from_url(image_ask_first_3_url)\n",
    "image_dont_do_this_3 = load_image_from_url(image_dont_do_this_3_url)\n",
    "\n",
    "prompt1 = \"\"\"\n",
    "Consider the following two images:\n",
    "Image 1:\n",
    "\"\"\"\n",
    "prompt2 = \"\"\"\n",
    "Image 2:\n",
    "\"\"\"\n",
    "prompt3 = \"\"\"\n",
    "1. What is shown in Image 1 and Image 2?\n",
    "2. What is similar between the two images?\n",
    "3. What is difference between Image 1 and Image 2 in terms of the text ?\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb6c29",
   "metadata": {},
   "source": [
    "#### Create an input for the multimodal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420a9d34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = [\n",
    "    Part.from_text(prompt1),\n",
    "    Part.from_image(image_ask_first_3),\n",
    "    Part.from_text(prompt2),\n",
    "    Part.from_image(image_dont_do_this_3),\n",
    "    Part.from_text(prompt3)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eaa88b",
   "metadata": {},
   "source": [
    "#### Set configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc9ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_config =  {\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 0.8,\n",
    "    \"top_k\": 20\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78eecbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Generate responses from the multimodal model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74696b35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responses = 'Here's a breakdown of the images:\n",
      "\n",
      "**1. What is shown in Image 1 and Image 2?**\n",
      "\n",
      "*   **Image 1:** Shows a webpage for the Wisahawkeen Public Library announcing a partnership with \"Grow with Google\". It also includes a warning about sponsorships and partnerships, advising those with existing deals with Google to contact their Google contact for review.\n",
      "\n",
      "*   **Image 2:** Displays the \"Finder.ly\" logo, which is a colorful design. Below the logo, there's a warning against imitating Google's logo or visual identity, including color combinations, graphic designs, product icons, or imagery associated with Google.\n",
      "\n",
      "**2. What is similar between the two images?**\n",
      "\n",
      "*   **Connection to Google:** Both images relate to Google. Image 1 shows a partnership with \"Grow with Google,\" and Image 2 warns against imitating Google's visual identity.\n",
      "*   **Warnings/Guidelines:** Both images include text that serves as a warning or guideline. Image 1 warns about sponsorships, and Image 2 warns against imitating Google's branding.\n",
      "\n",
      "**3. What is the difference between Image 1 and Image 2 in terms of the text?**\n",
      "\n",
      "*   **Content:** The text in Image 1 focuses on sponsorships and partnerships with Google, advising individuals with existing deals to contact their Google contact. The text in Image 2 focuses on protecting Google's brand identity by warning against imitation.\n",
      "*   **Purpose:** The text in Image 1 is informative and advisory, providing guidance on how to handle existing Google sponsorships. The text in Image 2 is cautionary, aiming to prevent the misuse or imitation of Google's brand elements.\n",
      "*   **Tone:** The tone in Image 1 is professional and helpful. The tone in Image 2 is more assertive, emphasizing the importance of not imitating Google's brand.'\n"
     ]
    }
   ],
   "source": [
    "responses =  multimodal_model.generate_content(\n",
    "        contents,\n",
    "        generation_config=generation_config\n",
    "    )\n",
    "print(f\"responses = '{responses.text}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16501a73",
   "metadata": {},
   "source": [
    "#### Display the prompt and responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28236144",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Contenido: Texto - '\n",
      "Consider the following two images:\n",
      "Image 1:\n",
      "'\n",
      "- Contenido: Desconocido\n",
      "- Contenido: Texto - '\n",
      "Image 2:\n",
      "'\n",
      "- Contenido: Desconocido\n",
      "- Contenido: Texto - '\n",
      "1. What is shown in Image 1 and Image 2?\n",
      "2. What is similar between the two images?\n",
      "3. What is difference between Image 1 and Image 2 in terms of the text ?\n",
      "'\n",
      "\n",
      "--- Respuesta del Modelo ---\n",
      "Here's a breakdown of the images:\n",
      "\n",
      "**1. What is shown in Image 1 and Image 2?**\n",
      "\n",
      "*   **Image 1:** Shows a webpage for the Wisahawkeen Public Library announcing a partnership with \"Grow with Google\". It also includes a warning about sponsorships and partnerships, advising those with existing deals with Google to contact their Google contact for review.\n",
      "\n",
      "*   **Image 2:** Displays the \"Finder.ly\" logo, which is a colorful design. Below the logo, there's a warning against imitating Google's logo or visual identity, including color combinations, graphic designs, product icons, or imagery associated with Google.\n",
      "\n",
      "**2. What is similar between the two images?**\n",
      "\n",
      "*   **Connection to Google:** Both images relate to Google. Image 1 shows a partnership with \"Grow with Google,\" and Image 2 warns against imitating Google's visual identity.\n",
      "*   **Warnings/Guidelines:** Both images include text that serves as a warning or guideline. Image 1 warns about sponsorships, and Image 2 warns against imitating Google's branding.\n",
      "\n",
      "**3. What is the difference between Image 1 and Image 2 in terms of the text?**\n",
      "\n",
      "*   **Content:** The text in Image 1 focuses on sponsorships and partnerships with Google, advising individuals with existing deals to contact their Google contact. The text in Image 2 focuses on protecting Google's brand identity by warning against imitation.\n",
      "*   **Purpose:** The text in Image 1 is informative and advisory, providing guidance on how to handle existing Google sponsorships. The text in Image 2 is cautionary, aiming to prevent the misuse or imitation of Google's brand elements.\n",
      "*   **Tone:** The tone in Image 1 is professional and helpful. The tone in Image 2 is more assertive, emphasizing the importance of not imitating Google's brand.\n"
     ]
    }
   ],
   "source": [
    "for item in contents:\n",
    "    if hasattr(item, 'part_data') and hasattr(item.part_data, 'inline_data'):\n",
    "        if item.part_data.inline_data.mime_type.startswith('image'):\n",
    "            print(\"- Contenido: Imagen (tipo MIME: {})\".format(item.part_data.inline_data.mime_type))\n",
    "        elif item.part_data.inline_data.mime_type == 'text/plain':\n",
    "            print(\"- Contenido: Texto - '{}'\".format(item.text))\n",
    "        else:\n",
    "            print(\"- Contenido: Otro tipo de dato\")\n",
    "    elif hasattr(item, 'text'):\n",
    "        print(\"- Contenido: Texto - '{}'\".format(item.text))\n",
    "    else:\n",
    "        print(\"- Contenido: Desconocido\")\n",
    "\n",
    "print(\"\\n--- Respuesta del Modelo ---\")\n",
    "if hasattr(responses, 'text'):\n",
    "    print(responses.text)\n",
    "else:\n",
    "    print(\"La respuesta del modelo no contiene texto.\")\n",
    "    print(\"Respuesta completa del modelo:\", responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b238a1a4-7b7c-463f-af54-d853f1786b73",
   "metadata": {},
   "source": [
    "\n",
    "### Task 1.6. Retrieve extra information beyond the video\n",
    "\n",
    "#### Explore the variables of the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1668408-6c55-460f-b687-5916b417ed85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the following questions using the video only:\n",
    "\n",
    "How does the advertisement appeal to its target audience through its messaging and imagery?\n",
    "What overall message or takeaway does the advertisement convey about the brand and its products?\n",
    "Are there any symbolic elements or motifs used throughout the advertisement to reinforce its central themes?\n",
    "What is the best hashtag for this video based on the description ?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#CONFIGURAMOS EL VIDEO\n",
    "\n",
    "video = Part.from_uri(\n",
    "    uri=\"gs://spls/gsp520/google-pixel-8-pro.mp4\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868429f1",
   "metadata": {},
   "source": [
    "#### Create an input for the multimodal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec4cd5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = [Part.from_text(prompt), video]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b46261e",
   "metadata": {},
   "source": [
    "#### Generate responses from the multimodal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb93f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responses = 'Okay, here are the answers based solely on the information presented in the video:\n",
      "\n",
      "*   **How does the advertisement appeal to its target audience through its messaging and imagery?**\n",
      "\n",
      "    The advertisement appeals to the target audience by showcasing various situations and scenarios where people use the phone's features. It uses vibrant visuals, catchy music, and relatable situations to engage the viewer. It highlights features such as background noise reduction, object eraser, and ensuring everyone in a group photo is smiling to entice the target audience. The fast-paced editing and modern aesthetic appeal to a younger demographic.\n",
      "\n",
      "*   **What overall message or takeaway does the advertisement convey about the brand and its products?**\n",
      "\n",
      "    The advertisement conveys that the Google Pixel 8 Pro is an innovative and versatile phone that utilizes AI and editing features to improve photography and user experience. The overall message is that with Pixel, anyone can make moments pop, ensure everyone is smiling in photos, and change everything in a photo. It emphasizes the phone's advanced technology and how it can be used in everyday life.\n",
      "\n",
      "*   **Are there any symbolic elements or motifs used throughout the advertisement to reinforce its central themes?**\n",
      "\n",
      "    The use of editing features throughout the advertisement symbolizes the power and ease of manipulating and enhancing images with the Google Pixel 8 Pro. Additionally, there are multiple instances of groups of friends taking photographs which symbolize the ease of taking photographs in social gatherings.\n",
      "\n",
      "*   **What is the best hashtag for this video based on the description?**\n",
      "\n",
      "    The best hashtag for this video would be #Pixel8Pro.'\n"
     ]
    }
   ],
   "source": [
    "responses =  multimodal_model.generate_content(contents)\n",
    "print(f\"responses = '{responses.text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa426629",
   "metadata": {},
   "source": [
    "#### Display the prompt and responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492f1f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prompt (Preguntas y Video) ---\n",
      "- Texto del Prompt:\n",
      "\n",
      "Answer the following questions using the video only:\n",
      "\n",
      "How does the advertisement appeal to its target audience through its messaging and imagery?\n",
      "What overall message or takeaway does the advertisement convey about the brand and its products?\n",
      "Are there any symbolic elements or motifs used throughout the advertisement to reinforce its central themes?\n",
      "What is the best hashtag for this video based on the description ?\n",
      "\n",
      "\n",
      "- Contenido: Otro tipo de dato\n",
      "\n",
      "--- Respuesta del Modelo ---\n",
      "Okay, here are the answers based solely on the information presented in the video:\n",
      "\n",
      "*   **How does the advertisement appeal to its target audience through its messaging and imagery?**\n",
      "\n",
      "    The advertisement appeals to the target audience by showcasing various situations and scenarios where people use the phone's features. It uses vibrant visuals, catchy music, and relatable situations to engage the viewer. It highlights features such as background noise reduction, object eraser, and ensuring everyone in a group photo is smiling to entice the target audience. The fast-paced editing and modern aesthetic appeal to a younger demographic.\n",
      "\n",
      "*   **What overall message or takeaway does the advertisement convey about the brand and its products?**\n",
      "\n",
      "    The advertisement conveys that the Google Pixel 8 Pro is an innovative and versatile phone that utilizes AI and editing features to improve photography and user experience. The overall message is that with Pixel, anyone can make moments pop, ensure everyone is smiling in photos, and change everything in a photo. It emphasizes the phone's advanced technology and how it can be used in everyday life.\n",
      "\n",
      "*   **Are there any symbolic elements or motifs used throughout the advertisement to reinforce its central themes?**\n",
      "\n",
      "    The use of editing features throughout the advertisement symbolizes the power and ease of manipulating and enhancing images with the Google Pixel 8 Pro. Additionally, there are multiple instances of groups of friends taking photographs which symbolize the ease of taking photographs in social gatherings.\n",
      "\n",
      "*   **What is the best hashtag for this video based on the description?**\n",
      "\n",
      "    The best hashtag for this video would be #Pixel8Pro.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Prompt (Preguntas y Video) ---\")\n",
    "for item in contents:\n",
    "    if isinstance(item, str):\n",
    "        print(\"- Texto del Prompt:\")\n",
    "        print(item)\n",
    "    elif hasattr(item, 'part_data') and hasattr(item.part_data, 'inline_data') and item.part_data.inline_data.mime_type.startswith('video'):\n",
    "        print(\"- Contenido: Video (tipo MIME: {})\".format(item.part_data.inline_data.mime_type))\n",
    "        print(\"- URI del Video:\", item.uri)\n",
    "    elif hasattr(item, 'text'):\n",
    "        print(\"- Texto del Prompt:\")\n",
    "        print(item.text)\n",
    "    elif hasattr(item, 'uri') and hasattr(item, 'mime_type') and item.mime_type.startswith('video'):\n",
    "        print(\"- Contenido: Video (tipo MIME: {})\".format(item.mime_type))\n",
    "        print(\"- URI del Video:\", item.uri)\n",
    "    else:\n",
    "        print(\"- Contenido: Otro tipo de dato\")\n",
    "\n",
    "print(\"\\n--- Respuesta del Modelo ---\")\n",
    "if hasattr(responses, 'text'):\n",
    "    print(responses.text)\n",
    "else:\n",
    "    print(\"La respuesta del modelo no contiene texto.\")\n",
    "    print(\"Respuesta completa del modelo:\", responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42950158-1e1f-40bd-97b4-d18474dd86fe",
   "metadata": {},
   "source": [
    "## Task 2. Retrieving and integrating knowledge with multimodal retrieval augmented generation (RAG)\n",
    "\n",
    "To complete Task 2, follow the instructions at the top of each notebook cell:\n",
    "* Run the cells with the comment \"RUN THIS CELL AS IS\".\n",
    "* Complete and run the cells with the comment \"COMPLETE THE MISSING PART AND RUN THIS CELL\".\n",
    "\n",
    "For additional information about the available data and helper functions for Task 2, review the section named __Available data and helper functions for Task 2__ in the lab instructions.\n",
    "\n",
    "### Setup and requirements for Task 2\n",
    "\n",
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106e655-0da7-4eba-8595-706622ab7ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from vertexai.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    HarmCategory,\n",
    "    HarmBlockThreshold,\n",
    "    Image,\n",
    "    Part,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ce78c",
   "metadata": {},
   "source": [
    "#### Load the Gemini 2.0 Flash model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be19c04e-b7d2-4439-a0bd-58ffa0c1f2dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multimodal_model = GenerativeModel(\"gemini-2.0-flash-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb962cea-0b31-43f6-b757-90bc1ff1cd5b",
   "metadata": {},
   "source": [
    "#### Download custom Python modules and utilities \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa75ac-3512-4ee2-a4b6-e8e926d19587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import sys\n",
    "\n",
    "if not os.path.exists(\"utils\"):\n",
    "    os.makedirs(\"utils\")\n",
    "\n",
    "\n",
    "\n",
    "url_prefix = \"https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/retrieval-augmented-generation/utils/\"\n",
    "files = [\"intro_multimodal_rag_utils.py\"]\n",
    "\n",
    "for fname in files:\n",
    "    urllib.request.urlretrieve(f\"{url_prefix}/{fname}\", filename=f\"utils/{fname}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a4c367-585d-4e15-883d-ed0a674475f1",
   "metadata": {},
   "source": [
    "#### Get documents and images from Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f06b4-4e9c-449b-94f3-4175b37777c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building synchronization state...\n",
      "Starting synchronization...\n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rsync -r gs://spls/gsp520 .\n",
    "print(\"Download completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b72d16-d530-424b-934a-ebf091bc254c",
   "metadata": {},
   "source": [
    "### Task 2.1. Build metadata of documents containing text and images\n",
    "\n",
    "\n",
    "#### Import helper functions to build metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e1759-0c37-44ff-9f2b-85ee427e7f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.intro_multimodal_rag_utils import get_document_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcfd03c-9713-4621-b5e5-fee645d338e9",
   "metadata": {},
   "source": [
    "#### Explore the variables of the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b6d28-4d64-4e03-b395-23bd2c8b6bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pdf_folder_path = \"Google_Branding/\"  \n",
    "\n",
    "image_description_prompt = \"\"\"Explain what is going on in the image.\n",
    "If it's a table, extract all elements of the table.\n",
    "If it's a graph, explain the findings in the graph.\n",
    "Do not include any numbers that are not mentioned in the image.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60611e48",
   "metadata": {},
   "source": [
    "\n",
    "#### Extract and store metadata of text and images from a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9d2331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Processing the file: --------------------------------- Google_Branding/Google_terms_of_service_en_us.pdf \n",
      "\n",
      "\n",
      "Processing page: 1\n",
      "Processing page: 2\n",
      "Processing page: 3\n",
      "Processing page: 4\n",
      "Processing page: 5\n",
      "Processing page: 6\n",
      "Processing page: 7\n",
      "Processing page: 8\n",
      "Processing page: 9\n",
      "Processing page: 10\n",
      "Processing page: 11\n",
      "Processing page: 12\n",
      "Processing page: 13\n",
      "Processing page: 14\n",
      "Processing page: 15\n",
      "Processing page: 16\n",
      "\n",
      "\n",
      " --- Completed processing. ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generative_multimodal_model = GenerativeModel(\"gemini-pro-vision\")\n",
    "image_save_dir = \"extracted_images\"\n",
    "\n",
    "text_metadata_df, image_metadata_df = get_document_metadata(\n",
    "    pdf_folder_path=pdf_folder_path,\n",
    "    generative_multimodal_model=generative_multimodal_model,\n",
    "    image_save_dir=image_save_dir,\n",
    "    image_description_prompt=image_description_prompt\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\n --- Completed processing. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96cd147-4ce1-4110-9c5b-d755e7a07457",
   "metadata": {},
   "source": [
    "#### Inspect the processed text metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f471508-1a38-4e3b-a4be-47e82acaf54b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Primeras filas de text_metadata_df ---\n",
      "                           file_name  page_num  \\\n",
      "0  Google_terms_of_service_en_us.pdf         1   \n",
      "1  Google_terms_of_service_en_us.pdf         1   \n",
      "2  Google_terms_of_service_en_us.pdf         2   \n",
      "3  Google_terms_of_service_en_us.pdf         2   \n",
      "4  Google_terms_of_service_en_us.pdf         3   \n",
      "\n",
      "                                                text  \\\n",
      "0  GOOGLE TERMS OF SERVICE\\nEffective January 5, ...   \n",
      "1  GOOGLE TERMS OF SERVICE\\nEffective January 5, ...   \n",
      "2  Google services are provided by, and youre con...   \n",
      "3  Google services are provided by, and youre con...   \n",
      "4  apps and sites (like Search and Maps)\\nplatfor...   \n",
      "\n",
      "                                 text_embedding_page  chunk_number  \\\n",
      "0  [-0.012991457246243954, 0.00233408878557384, 0...             1   \n",
      "1  [-0.012991457246243954, 0.00233408878557384, 0...             2   \n",
      "2  [-0.027467481791973114, -0.03269978240132332, ...             1   \n",
      "3  [-0.027467481791973114, -0.03269978240132332, ...             2   \n",
      "4  [-0.024841992184519768, -0.016507208347320557,...             1   \n",
      "\n",
      "                                          chunk_text  \\\n",
      "0  GOOGLE TERMS OF SERVICE\\nEffective January 5, ...   \n",
      "1  ongs to you, Google, or others\\nIn case of pro...   \n",
      "2  Google services are provided by, and youre con...   \n",
      "3  \\nto use our services if you agree to follow t...   \n",
      "4  apps and sites (like Search and Maps)\\nplatfor...   \n",
      "\n",
      "                                text_embedding_chunk  \n",
      "0  [-0.005565959494560957, 0.0008999718702398241,...  \n",
      "1  [-0.02242434397339821, -0.02287789061665535, -...  \n",
      "2  [-0.030542202293872833, -0.03709811717271805, ...  \n",
      "3  [-0.010060024447739124, -0.006401533726602793,...  \n",
      "4  [-0.022818822413682938, -0.026401124894618988,...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"--- Primeras filas de text_metadata_df ---\")\n",
    "print(text_metadata_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed0c6a-3d40-497b-b2c5-4a86c3b65c8d",
   "metadata": {},
   "source": [
    "#### Import the helper functions to implement RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4580d12-94a1-4e1b-8ff6-587916c85241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.intro_multimodal_rag_utils import (\n",
    "    get_similar_text_from_query,\n",
    "    print_text_to_text_citation,\n",
    "    get_similar_image_from_query,\n",
    "    print_text_to_image_citation,\n",
    "    get_gemini_response,\n",
    "    display_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f110046a-0615-4836-8776-113bba1b4088",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Task 2.2. Create a user query\n",
    "\n",
    "#### Explore the variables of the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad2d8f5-f937-44fc-9c2d-2a1426134bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CREAMOS LA CONSULTA\n",
    "\n",
    "query = \"\"\"Questions:\n",
    " - What are the key expectations that users can have from Google regarding the provision and development of its services?\n",
    "- What specific rules and guidelines are established for users when using Google services?\n",
    "- How does Google handle intellectual property rights related to the content found within its services, including content owned by users, Google, and third parties? \n",
    "- What legal rights and remedies are available to users in case of problems or disagreements with Google?\n",
    "- How do the service-specific additional terms interact with these general Terms of Service, and which terms take precedence in case of any conflicts?\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1fa0d-3b6f-44ff-bcbf-8c8b184f9ba7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Task 2.3. Get all relevant text chunks\n",
    "\n",
    "#### Retrieve relevant chunks of text based on the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc25d9-2d7e-433e-a5df-8d38eae9e75f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "matching_results_chunks_data = get_similar_text_from_query(\n",
    "    query=query,\n",
    "    text_metadata_df=text_metadata_df,\n",
    "    column_name=\"text_embedding_page\"  # Reemplaza con el nombre real de la columna\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4ec297-ca76-4cee-a008-c22002a0f7d3",
   "metadata": {},
   "source": [
    "#### Display the first item of the text chunk dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d72676-9721-4ade-9342-5ffa4dec45ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Primer ítem de matching_results_chunks_data ---\n",
      "(0, {'file_name': 'Google_terms_of_service_en_us.pdf', 'page_num': np.int64(1), 'cosine_score': 0.87, 'chunk_number': np.int64(1), 'chunk_text': 'GOOGLE TERMS OF SERVICE\\nEffective January 5, 2022\\nArchived versions\\nWhats covered in these terms\\nWe know its tempting to skip these Terms of Service, but\\nits important to establish what you can expect from us as\\nyou use Google services, and what we expect from you.\\nThese Terms of Service reflect the way Googles business works, the laws that apply to our company, and\\ncertain things weve always believed to be true. As a result, these Terms of Service help define Googles\\nrelationship with you as you interact with our services. For example, these terms include the following topic\\nheadings:\\nWhat you can expect from us, which describes how we provide and develop our services\\nWhat we expect from you, which establishes certain rules for using our services\\nContent in Google services, which describes the intellectual property rights to the content you find in our\\nservices  whether that content belongs to you, Google, or others\\nIn case of problems or disagreements, which describes other legal rig'})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"--- Primer ítem de matching_results_chunks_data ---\")\n",
    "if matching_results_chunks_data:\n",
    "    first_item = list(matching_results_chunks_data.items())[0]\n",
    "    print(first_item)\n",
    "else:\n",
    "    print(\"El diccionario matching_results_chunks_data está vacío.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f86a088-41c6-4bd2-8fc7-45f0a7e8a2e4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Task 2.4. Create context_text\n",
    "\n",
    "#### Create a list to store the combined chunks of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1595d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LISTA VACIA\n",
    "context_text = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95503358",
   "metadata": {},
   "source": [
    "#### Iterate through each item in the text chunks dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeddeea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto combinado:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_text = \"\"\n",
    "for key, value in matching_results_chunks_data.items():\n",
    "     if isinstance(value, dict) and 'chunk' in value:\n",
    "       combined_text += value['chunk'] + \" \" \n",
    "\n",
    "\n",
    "print(\"Texto combinado:\")\n",
    "print(combined_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b14e4b",
   "metadata": {},
   "source": [
    "#### Join all the text chunks and store in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc954cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto final combinado:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_context_text = \"\\n\".join(context_text)\n",
    "\n",
    "\n",
    "print(\"Texto final combinado:\")\n",
    "print(final_context_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cba9b5",
   "metadata": {},
   "source": [
    "\n",
    "### Task 2.5. Pass context to Gemini\n",
    "\n",
    "#### Explore the variables of the task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8241d2-7b7e-48c8-a7bd-1db5bcdb115f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prompt Generado ---\n",
      " Instructions: Answer in Markdown format, including bullet points, headings, and any other relevant formatting for readability. Compare the images and the text provided as Context: to answer multiple Question:\n",
      "Make sure to think thoroughly before answering the question and put the necessary steps to arrive at the answer in bullet points for easy explainability.\n",
      "If unsure, respond, \"Not enough context to answer\".\n",
      "\n",
      "Context:\n",
      " - Text Context:\n",
      " \n",
      "\n",
      "\n",
      "Questions:\n",
      " - What are the key expectations that users can have from Google regarding the provision and development of its services?\n",
      "- What specific rules and guidelines are established for users when using Google services?\n",
      "- How does Google handle intellectual property rights related to the content found within its services, including content owned by users, Google, and third parties? \n",
      "- What legal rights and remedies are available to users in case of problems or disagreements with Google?\n",
      "- How do the service-specific additional terms interact with these general Terms of Service, and which terms take precedence in case of any conflicts?\n",
      " \n",
      "\n",
      "Answer:\n",
      "\n",
      "--- Prompt Generado ---\n",
      " Instructions: Answer in Markdown format, including bullet points, headings, and any other relevant formatting for readability. Compare the images and the text provided as Context: to answer multiple Question:\n",
      "Make sure to think thoroughly before answering the question and put the necessary steps to arrive at the answer in bullet points for easy explainability.\n",
      "If unsure, respond, \"Not enough context to answer\".\n",
      "\n",
      "Context:\n",
      " - Text Context:\n",
      " \n",
      "\n",
      "\n",
      "Questions:\n",
      " - What are the key expectations that users can have from Google regarding the provision and development of its services?\n",
      "- What specific rules and guidelines are established for users when using Google services?\n",
      "- How does Google handle intellectual property rights related to the content found within its services, including content owned by users, Google, and third parties? \n",
      "- What legal rights and remedies are available to users in case of problems or disagreements with Google?\n",
      "- How do the service-specific additional terms interact with these general Terms of Service, and which terms take precedence in case of any conflicts?\n",
      " \n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PROVEEMOS LAS VARIABLES\n",
    "\n",
    "final_context_text = \"\\n\".join(context_text)\n",
    "\n",
    "prompt = f\"\"\" Instructions: Answer in Markdown format, including bullet points, headings, and any other relevant formatting for readability. Compare the images and the text provided as Context: to answer multiple Question:\n",
    "Make sure to think thoroughly before answering the question and put the necessary steps to arrive at the answer in bullet points for easy explainability.\n",
    "If unsure, respond, \"Not enough context to answer\".\n",
    "\n",
    "Context:\n",
    " - Text Context:\n",
    " {final_context_text}\n",
    "\n",
    "\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Prompt Generado ---\")\n",
    "print(prompt)\n",
    "print(\"--- Prompt Generado ---\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "35e93396-3ebd-4427-b406-42b66a232ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markdown\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: markdown\n",
      "Successfully installed markdown-3.8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46376c65",
   "metadata": {},
   "source": [
    "#### Generate Gemini response with streaming output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe99d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Recibiendo y formateando respuesta ---\n",
      "\n",
      "Since no images or text context were provided, I cannot answer the questions.\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "Not enough context to answer.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p>Since no images or text context were provided, I cannot answer the questions.</p>\n",
       "<p><strong>Answer:</strong></p>\n",
       "<p>Not enough context to answer.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "from utils.intro_multimodal_rag_utils import get_gemini_response\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
    "import markdown \n",
    "\n",
    "if not 'final_context_text' in globals() or not final_context_text.strip():\n",
    "    final_context_text = \" No context provided.\" \n",
    "\n",
    "if not 'query' in globals():\n",
    "    query = \"What is this about?\"\n",
    "\n",
    "multimodal_model = GenerativeModel(model_name=\"gemini-2.0-flash-001\")\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0.3,\n",
    "    top_p=0.8,\n",
    "    top_k=20,\n",
    "    max_output_tokens=1024,\n",
    "\n",
    "prompt = f\"\"\"Instructions: Compare the images and the text provided as Context: to answer multiple Questions:\n",
    "Make sure to think thoroughly before answering the question and put the necessary steps to arrive at the answer in bullet points for easy explainability.\n",
    "If unsure, respond, \"Not enough context to answer\".\n",
    "\n",
    "Context:\n",
    "- Text Context:\n",
    "{final_context_text}\n",
    "\n",
    "{query}\n",
    "\n",
    "Answer in Markdown format, including bullet points, headings, and any other relevant formatting for readability.\n",
    "\"\"\"\n",
    "\n",
    "responses = get_gemini_response(\n",
    "    multimodal_model,\n",
    "    prompt,\n",
    "    generation_config=generation_config,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "def mostrar_contenido_markdown(responses):\n",
    "    \"\"\"\n",
    "    Junta todos los chunks del modelo, los convierte de Markdown a HTML, y los muestra.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Recibiendo y formateando respuesta ---\\n\")\n",
    "    full_response = \"\"\n",
    "\n",
    "    for chunk in responses:\n",
    "        \n",
    "        text = \"\"\n",
    "        if isinstance(chunk, str):\n",
    "            text = chunk\n",
    "        elif hasattr(chunk, \"text\"):\n",
    "            text = chunk.text\n",
    "        else:\n",
    "            text = str(chunk)\n",
    "\n",
    "        print(f\"{text}\", end=\"\")  \n",
    "        full_response += text\n",
    "\n",
    "\n",
    "    html_output = markdown.markdown(full_response)\n",
    "    display(HTML(html_output))\n",
    "\n",
    "mostrar_contenido_markdown(responses)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
